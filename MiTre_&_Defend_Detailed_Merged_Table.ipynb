{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMtwt9wTcZMF7BrTNYJoIuq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kolawole-a2/Kola_Projects/blob/main/MiTre_%26_Defend_Detailed_Merged_Table.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PATCH CELL: fix \"unhashable list\" by stringifying list columns before drop_duplicates\n",
        "\n",
        "import os, re, io, zipfile\n",
        "import pandas as pd\n",
        "import requests\n",
        "from google.colab import files\n",
        "\n",
        "ATTACK_CSV = \"/content/attack_techniques.csv\"\n",
        "PAIRWISE_CSV = \"/content/attack_d3fend_merged.csv\"\n",
        "MASTER_CSV = \"/content/attack_defense_master.csv\"\n",
        "ZIP_PATH = \"/content/mitre_attack_d3fend_tables.zip\"\n",
        "\n",
        "D3FEND_JSON_URL  = \"https://d3fend.mitre.org/api/ontology/inference/d3fend-full-mappings.json\"\n",
        "D3FEND_CSV_URL   = \"https://d3fend.mitre.org/api/ontology/inference/d3fend-full-mappings.csv\"\n",
        "\n",
        "def fetch_json(url: str):\n",
        "    r = requests.get(url, timeout=60, headers={\"User-Agent\":\"colab-mitre-builder\"})\n",
        "    r.raise_for_status()\n",
        "    return r.json()\n",
        "\n",
        "def fetch_text(url: str) -> str:\n",
        "    r = requests.get(url, timeout=60, headers={\"User-Agent\":\"colab-mitre-builder\"})\n",
        "    r.raise_for_status()\n",
        "    return r.text\n",
        "\n",
        "def extract_tids(text) -> list:\n",
        "    if pd.isna(text): return []\n",
        "    return re.findall(r\"(T\\d{4}(?:\\.\\d{3})?)\", str(text))\n",
        "\n",
        "def infer_cat(name: str) -> str:\n",
        "    key = (name or \"\").lower()\n",
        "    for cat in [\"harden\",\"isolate\",\"detect\",\"deceive\",\"evict\",\"neutralize\",\"recover\",\"resilience\",\"respond\"]:\n",
        "        if cat in key:\n",
        "            return cat.capitalize()\n",
        "    return \"\"\n",
        "\n",
        "def load_d3fend_schema_agnostic() -> pd.DataFrame:\n",
        "    # Try CSV first (more stable), then JSON\n",
        "    try:\n",
        "        raw = pd.read_csv(io.StringIO(fetch_text(D3FEND_CSV_URL)))\n",
        "        rows = []\n",
        "        for _, r in raw.iterrows():\n",
        "            tids = set()\n",
        "            for v in r.to_list():\n",
        "                tids.update(extract_tids(v))\n",
        "            if not tids:\n",
        "                continue\n",
        "            # D3FEND name (best-effort)\n",
        "            d3_name = \"\"\n",
        "            for v in r.to_list():\n",
        "                s = str(v)\n",
        "                if \"d3f:\" in s or \"d3fend\" in s.lower():\n",
        "                    d3_name = s.split(\":\")[-1] if \":\" in s else s\n",
        "                    break\n",
        "            # Category, relation (best-effort)\n",
        "            d3_cat = \"\"\n",
        "            relation = \"\"\n",
        "            for c in raw.columns:\n",
        "                lc = c.lower()\n",
        "                if not d3_cat and (\"category\" in lc or \"tactic\" in lc):\n",
        "                    d3_cat = str(r[c])\n",
        "                if not relation and (\"relation\" in lc or \"predicate\" in lc):\n",
        "                    relation = str(r[c])\n",
        "            if not d3_cat:\n",
        "                d3_cat = infer_cat(d3_name)\n",
        "            for tid in tids:\n",
        "                rows.append({\n",
        "                    \"attack_technique_id\": tid,\n",
        "                    \"d3fend_name\": d3_name,\n",
        "                    \"d3fend_category\": d3_cat,\n",
        "                    \"relation\": relation,\n",
        "                    \"d3fend_raw\": d3_name\n",
        "                })\n",
        "        return pd.DataFrame(rows).drop_duplicates()\n",
        "    except Exception:\n",
        "        data = fetch_json(D3FEND_JSON_URL)\n",
        "        bindings = data.get(\"results\", {}).get(\"bindings\", []) or data.get(\"bindings\", []) or []\n",
        "        rows = []\n",
        "        def label(d): return d.get(\"label\") or d.get(\"value\") or \"\"\n",
        "        for b in bindings:\n",
        "            subj = label(b.get(\"s\", {})) or label(b.get(\"subject\", {}))\n",
        "            pred = label(b.get(\"p\", {})) or label(b.get(\"predicate\", {}))\n",
        "            obj  = label(b.get(\"o\", {})) or label(b.get(\"object\", {}))\n",
        "            tids = set(extract_tids(\" \".join([subj, pred, obj])))\n",
        "            if not tids:\n",
        "                continue\n",
        "            d3_name = \"\"\n",
        "            for t in (subj, obj):\n",
        "                if \"d3f:\" in t or \"d3fend\" in t.lower():\n",
        "                    d3_name = t.split(\":\")[-1] if \":\" in t else t\n",
        "                    break\n",
        "            d3_cat = infer_cat(d3_name)\n",
        "            for tid in tids:\n",
        "                rows.append({\n",
        "                    \"attack_technique_id\": tid,\n",
        "                    \"d3fend_name\": d3_name,\n",
        "                    \"d3fend_category\": d3_cat,\n",
        "                    \"relation\": pred or \"\",\n",
        "                    \"d3fend_raw\": d3_name\n",
        "                })\n",
        "        return pd.DataFrame(rows).drop_duplicates()\n",
        "\n",
        "# 1) Load ATT&CK techniques already created\n",
        "df_attack = pd.read_csv(ATTACK_CSV)\n",
        "\n",
        "# 2) Load D3FEND mappings\n",
        "df_d3 = load_d3fend_schema_agnostic()\n",
        "# Normalize technique IDs to canonical T####(.###)\n",
        "def norm_tid(x):\n",
        "    if pd.isna(x): return None\n",
        "    m = re.search(r\"(T\\d{4}(?:\\.\\d{3})?)\", str(x))\n",
        "    return m.group(1) if m else None\n",
        "df_d3[\"attack_technique_id\"] = df_d3[\"attack_technique_id\"].map(norm_tid)\n",
        "df_d3 = df_d3.dropna(subset=[\"attack_technique_id\"]).drop_duplicates()\n",
        "\n",
        "# 3) Merge (left join to keep all techniques)\n",
        "merged_left = df_attack.merge(\n",
        "    df_d3,\n",
        "    left_on=\"technique_id\",\n",
        "    right_on=\"attack_technique_id\",\n",
        "    how=\"left\"\n",
        ")\n",
        "\n",
        "# 4) Stringify list-like columns BEFORE any drop_duplicates\n",
        "def stringify(v):\n",
        "    if isinstance(v, list):\n",
        "        return \" | \".join(map(str, v))\n",
        "    return \"\" if pd.isna(v) else v\n",
        "\n",
        "for col in [\"tactics\",\"platforms\"]:\n",
        "    if col in merged_left.columns:\n",
        "        merged_left[col] = merged_left[col].apply(stringify)\n",
        "\n",
        "# 5) Pairwise crosswalk (mapped rows only)\n",
        "pairwise = merged_left.dropna(subset=[\"d3fend_name\"]).copy()\n",
        "pairwise_cols = [\n",
        "    \"attack_technique_id\",\"technique_name\",\"is_subtechnique\",\"parent_technique_id\",\"tactics\",\"platforms\",\n",
        "    \"d3fend_name\",\"d3fend_category\",\"relation\",\"d3fend_raw\"\n",
        "]\n",
        "for c in pairwise_cols:\n",
        "    if c not in pairwise.columns: pairwise[c] = \"\"\n",
        "pairwise = pairwise[pairwise_cols].drop_duplicates().reset_index(drop=True)\n",
        "pairwise.to_csv(PAIRWISE_CSV, index=False)\n",
        "\n",
        "# 6) Aggregated master (one row per technique, incl. unmapped)\n",
        "if not pairwise.empty:\n",
        "    agg = (\n",
        "        pairwise\n",
        "        .groupby(\"attack_technique_id\", dropna=True)\n",
        "        .agg({\n",
        "            \"d3fend_name\": lambda s: \" | \".join(sorted(set([x for x in s if str(x).strip()]))),\n",
        "            \"d3fend_category\": lambda s: \" | \".join(sorted(set([x for x in s if str(x).strip()]))),\n",
        "        })\n",
        "        .rename(columns={\"d3fend_name\":\"d3fend_names\",\"d3fend_category\":\"d3fend_categories\"})\n",
        "        .reset_index()\n",
        "    )\n",
        "    counts = pairwise.groupby(\"attack_technique_id\")[\"d3fend_name\"].nunique().reset_index(name=\"d3fend_count\")\n",
        "    agg = agg.merge(counts, on=\"attack_technique_id\", how=\"left\")\n",
        "else:\n",
        "    agg = pd.DataFrame(columns=[\"attack_technique_id\",\"d3fend_names\",\"d3fend_categories\",\"d3fend_count\"])\n",
        "\n",
        "master = df_attack.merge(agg, left_on=\"technique_id\", right_on=\"attack_technique_id\", how=\"left\")\n",
        "master[\"has_d3fend_mapping\"] = master[\"d3fend_count\"].fillna(0).astype(int).gt(0)\n",
        "if \"attack_technique_id\" in master.columns:\n",
        "    master.drop(columns=[\"attack_technique_id\"], inplace=True)\n",
        "master = master.sort_values([\"has_d3fend_mapping\",\"technique_id\",\"is_subtechnique\"], ascending=[False, True, True])\n",
        "\n",
        "master.to_csv(MASTER_CSV, index=False)\n",
        "\n",
        "# 7) Zip and download\n",
        "with zipfile.ZipFile(ZIP_PATH, \"w\", zipfile.ZIP_DEFLATED) as zf:\n",
        "    zf.write(ATTACK_CSV, arcname=os.path.basename(ATTACK_CSV))\n",
        "    zf.write(PAIRWISE_CSV, arcname=os.path.basename(PAIRWISE_CSV))\n",
        "    zf.write(MASTER_CSV, arcname=os.path.basename(MASTER_CSV))\n",
        "\n",
        "print(f\"Saved:\\n- {ATTACK_CSV}\\n- {PAIRWISE_CSV} ({len(pairwise)} rows)\\n- {MASTER_CSV} ({len(master)} rows)\")\n",
        "files.download(ZIP_PATH)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "9k4twMQa4217",
        "outputId": "38d31158-23e3-4424-899e-344c249abbac"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved:\n",
            "- /content/attack_techniques.csv\n",
            "- /content/attack_d3fend_merged.csv (1448 rows)\n",
            "- /content/attack_defense_master.csv (679 rows)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_2e5f435f-e023-4749-b927-2519c3537b1f\", \"mitre_attack_d3fend_tables.zip\", 569249)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}